A decoder only transformer with Muti-head Attention, KV Cache and ROPE.

(The code has not been confirmed to be absolutely correct. TAT)
